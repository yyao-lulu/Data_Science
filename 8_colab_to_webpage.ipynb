{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8_colab_to_webpage.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yyao-lulu/DeepLearning/blob/master/8_colab_to_webpage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "e1cDMWdOjJ2r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook (and the slides from lecture 8) will help you go straight from training a model in Colab to deploying it in a webpage with TensorFlow.js - without having to leave the browser."
      ]
    },
    {
      "metadata": {
        "id": "248xIjNGCRU0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Configure this notebook to work with your GitHub account by populating these fields."
      ]
    },
    {
      "metadata": {
        "id": "Ft9uEY7UCH46",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "a11e94d1-693d-443f-e555-1ae52362515e"
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading https://files.pythonhosted.org/packages/8c/d3/f534d1d042465e0e66a04b0fa31dc1f13cfea7d8340017ef4cd649b9c3a0/tensorflowjs-0.6.7-py3-none-any.whl\n",
            "Collecting keras==2.2.2 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/7d/b1dedde8af99bd82f20ed7e9697aac0597de3049b1f786aa2aac3b9bd4da/Keras-2.2.2-py2.py3-none-any.whl (299kB)\n",
            "\u001b[K    100% |████████████████████████████████| 307kB 25.4MB/s \n",
            "\u001b[?25hCollecting numpy==1.15.1 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/94/7049fed8373c52839c8cde619acaf2c9b83082b935e5aa8c0fa27a4a8bcc/numpy-1.15.1-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 13.9MB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub==0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (0.1.1)\n",
            "Requirement already satisfied: six==1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.11.0)\n",
            "Requirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.8.0)\n",
            "Requirement already satisfied: tensorflow==1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.12.0)\n",
            "Collecting keras-applications==1.0.4 (from keras==2.2.2->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/90/8f327deaa37a71caddb59b7b4aaa9d4b3e90c0e76f8c2d1572005278ddc5/Keras_Applications-1.0.4-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 19.2MB/s \n",
            "\u001b[?25hCollecting keras-preprocessing==1.0.2 (from keras==2.2.2->tensorflowjs)\n",
            "  Downloading https://files.pythonhosted.org/packages/71/26/1e778ebd737032749824d5cba7dbd3b0cf9234b87ab5ec79f5f0403ca7e9/Keras_Preprocessing-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs) (3.13)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub==0.1.1->tensorflowjs) (3.6.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.32.2)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub==0.1.1->tensorflowjs) (40.6.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->tensorflowjs) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->tensorflowjs) (3.0.1)\n",
            "\u001b[31mtensorflow 1.12.0 has requirement keras-applications>=1.0.6, but you'll have keras-applications 1.0.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mtensorflow 1.12.0 has requirement keras-preprocessing>=1.0.5, but you'll have keras-preprocessing 1.0.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, keras-applications, keras-preprocessing, keras, tensorflowjs\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "  Found existing installation: Keras-Applications 1.0.6\n",
            "    Uninstalling Keras-Applications-1.0.6:\n",
            "      Successfully uninstalled Keras-Applications-1.0.6\n",
            "  Found existing installation: Keras-Preprocessing 1.0.5\n",
            "    Uninstalling Keras-Preprocessing-1.0.5:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.0.5\n",
            "  Found existing installation: Keras 2.2.4\n",
            "    Uninstalling Keras-2.2.4:\n",
            "      Successfully uninstalled Keras-2.2.4\n",
            "Successfully installed keras-2.2.2 keras-applications-1.0.4 keras-preprocessing-1.0.2 numpy-1.15.1 tensorflowjs-0.6.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g4k9_Ke9CaOq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# your github username\n",
        "USER_NAME = \"yyao-lulu\" \n",
        "\n",
        "# the email associated with your commits\n",
        "# (may not matter if you leave it as this)\n",
        "USER_EMAIL = \"yyao.lulu@gmail.com\" \n",
        "\n",
        "# the user token you've created (see the lecture 8 slides for instructions)\n",
        "TOKEN = \"537642f03264e37b4c38284b808fa88002159648\" \n",
        "\n",
        "# site name\n",
        "# for example, if my user_name is \"foo\", then this notebook will create\n",
        "# a site at https://foo.github.io/{repo_path}/hw4/\n",
        "SITE_NAME = \"hw4\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dnPqmO8vDDwW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, run this cell to configure git."
      ]
    },
    {
      "metadata": {
        "id": "Q0IMoqVdCIb4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git config --global user.email {USER_NAME}\n",
        "!git config --global user.name  {USER_EMAIL}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XYfDxuMfDVas",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Clone your GitHub pages repo (see the lecture 8 slides for instructions on how to create one)."
      ]
    },
    {
      "metadata": {
        "id": "qRUyZiFqDUxt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "41b977f4-ad3e-427c-c1e5-07dab4114d0b"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "repo_path = 'DeepLearning'\n",
        "if not os.path.exists(os.path.join(os.getcwd(), repo_path)):\n",
        "  !git clone https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/{repo_path}"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeepLearning'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 9 (delta 0), reused 9 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (9/9), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qu4OA27iDU0e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "461c77dc-4f05-4ae7-ba82-09df7ead4ea4"
      },
      "cell_type": "code",
      "source": [
        "os.chdir(repo_path)\n",
        "!git pull"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KgISB_cAHPIs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a folder for your site."
      ]
    },
    {
      "metadata": {
        "id": "UAA6t4slF0nB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "project_path = os.path.join(os.getcwd(), SITE_NAME)\n",
        "if not os.path.exists(project_path): \n",
        "  os.mkdir(project_path)\n",
        "os.chdir(project_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DwYh8sXKHs3O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "These paths will be used by the converter script."
      ]
    },
    {
      "metadata": {
        "id": "ABggwdWMGe2h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY\n",
        "MODEL_DIR = os.path.join(project_path, \"model_js\")\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "  os.mkdir(MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TJpu2BkSUWe4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As an example, we will create and vectorize a few documents. (Check out https://www.gutenberg.org/ for a bunch of free e-books.)"
      ]
    },
    {
      "metadata": {
        "id": "Pgm8y7fWHxOI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A few snippets from Alice in Wonderland\n",
        "ex1 = \"Alice was beginning to get very tired of sitting by her sister on the bank.\"\n",
        "ex2 = \"Once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it.\"\n",
        "\n",
        "# Dracula\n",
        "ex3 = \"Buda-Pesth seems a wonderful place.\"\n",
        "ex4 = \"Left Munich at 8:35 P. M., on 1st May, arriving at Vienna early next morning.\"\n",
        "\n",
        "# Illiad\n",
        "ex5 = \"Scepticism was as much the result of knowledge, as knowledge is of scepticism.\"\n",
        "ex6 = \"To be content with what we at present know, is, for the most part, to shut our ears against conviction.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CASpAIgJalTp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = [ex1, ex2, ex3, ex4, ex5, ex6]\n",
        "y_train = [0, 0, 1, 1, 2, 2] # Indicating which book each sentence is from"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CVfStwZCYBAq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tokenize the documents, create a word index (word -> number)."
      ]
    },
    {
      "metadata": {
        "id": "HOHTxREVQalF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_len = 20\n",
        "num_words = 1000\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "# Fit the tokenizer on the training data\n",
        "t = Tokenizer(num_words=num_words)\n",
        "t.fit_on_texts(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mqyqHuLwWT-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "90c46c27-468f-4f8d-d0a4-deb141c37968"
      },
      "cell_type": "code",
      "source": [
        "print(t.word_index)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'the': 1, 'was': 2, 'to': 3, 'of': 4, 'at': 5, 'her': 6, 'sister': 7, 'on': 8, 'or': 9, 'had': 10, 'it': 11, 'scepticism': 12, 'as': 13, 'knowledge': 14, 'is': 15, 'alice': 16, 'beginning': 17, 'get': 18, 'very': 19, 'tired': 20, 'sitting': 21, 'by': 22, 'bank': 23, 'once': 24, 'twice': 25, 'she': 26, 'peeped': 27, 'into': 28, 'book': 29, 'reading': 30, 'but': 31, 'no': 32, 'pictures': 33, 'conversations': 34, 'in': 35, 'buda': 36, 'pesth': 37, 'seems': 38, 'a': 39, 'wonderful': 40, 'place': 41, 'left': 42, 'munich': 43, '8': 44, '35': 45, 'p': 46, 'm': 47, '1st': 48, 'may': 49, 'arriving': 50, 'vienna': 51, 'early': 52, 'next': 53, 'morning': 54, 'much': 55, 'result': 56, 'be': 57, 'content': 58, 'with': 59, 'what': 60, 'we': 61, 'present': 62, 'know': 63, 'for': 64, 'most': 65, 'part': 66, 'shut': 67, 'our': 68, 'ears': 69, 'against': 70, 'conviction': 71}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "feIAyrrxYFoU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here's how we vectorize a document."
      ]
    },
    {
      "metadata": {
        "id": "Jfi7tJbHTwIc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "792ea391-0a41-46e6-b1b5-3db26be8e6ad"
      },
      "cell_type": "code",
      "source": [
        "vectorized = t.texts_to_sequences([ex1])\n",
        "print(vectorized)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[16, 2, 17, 3, 18, 19, 20, 4, 21, 22, 6, 7, 8, 1, 23]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vUfL6MVhYHof",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Apply padding if necessary."
      ]
    },
    {
      "metadata": {
        "id": "rbghRbY5QaMV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "padded = pad_sequences(vectorized, maxlen=max_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9xwd6ND_UIKk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e025a5d0-8ffb-4998-c756-1507a9d5f836"
      },
      "cell_type": "code",
      "source": [
        "print(padded)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[16  2 17  3 18 19 20  4 21 22  6  7  8  1 23  0  0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C9NUXTTuYLZ0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will save the word index in metadata. Later, we'll use it to convert words typed in the browser to numbers for prediction."
      ]
    },
    {
      "metadata": {
        "id": "UpzusXHhULBr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "metadata = {\n",
        "  'word_index': t.word_index,\n",
        "  'max_len': max_len,\n",
        "  'vocabulary_size': num_words,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l57eA3ApZGsC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define a model."
      ]
    },
    {
      "metadata": {
        "id": "oLQeTh3uVqtj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "233c188c-89f6-4763-b9df-8165890c9929"
      },
      "cell_type": "code",
      "source": [
        "embedding_size = 8\n",
        "n_classes = 3\n",
        "epochs = 10\n",
        "\n",
        "import keras\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(num_words, embedding_size, input_shape=(max_len,)))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(3, activation='softmax'))\n",
        "model.compile('adam', 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 20, 8)             8000      \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 160)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 483       \n",
            "=================================================================\n",
            "Total params: 8,483\n",
            "Trainable params: 8,483\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6VOtCRJiYWZZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Prepare some training data."
      ]
    },
    {
      "metadata": {
        "id": "-Q8Y1ZuZYYKC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7d3fe525-24a4-40f1-c810-d371dcc6111e"
      },
      "cell_type": "code",
      "source": [
        "x_train = t.texts_to_sequences(x_train)\n",
        "x_train = pad_sequences(x_train, maxlen=max_len, padding='post')\n",
        "print(x_train)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[16  2 17  3 18 19 20  4 21 22  6  7  8  1 23  0  0  0  0  0]\n",
            " [25 26 10 27 28  1 29  6  7  2 30 31 11 10 32 33  9 34 35 11]\n",
            " [36 37 38 39 40 41  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [42 43  5 44 45 46 47  8 48 49 50  5 51 52 53 54  0  0  0  0]\n",
            " [12  2 13 55  1 56  4 14 13 14 15  4 12  0  0  0  0  0  0  0]\n",
            " [ 3 57 58 59 60 61  5 62 63 15 64  1 65 66  3 67 68 69 70 71]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VUWlD3jiX10c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "005eccbf-d05a-402a-a426-85fd7309b624"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=epochs)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 1.0888 - acc: 0.5000\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 856us/step - loss: 1.0817 - acc: 0.5000\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 1.0736 - acc: 0.5000\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 962us/step - loss: 1.0650 - acc: 0.6667\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 752us/step - loss: 1.0561 - acc: 0.6667\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 861us/step - loss: 1.0471 - acc: 0.8333\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 1.0380 - acc: 1.0000\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 949us/step - loss: 1.0288 - acc: 1.0000\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 1ms/step - loss: 1.0195 - acc: 1.0000\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 701us/step - loss: 1.0102 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdcb9676e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "y1YbPNWIenE5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Demo using the model to make predictions."
      ]
    },
    {
      "metadata": {
        "id": "KcmpKvKUY_hK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "110a3b8c-53fe-4f68-fbb4-a7c8c7e70746"
      },
      "cell_type": "code",
      "source": [
        "test_example = \"Left Munich at 8:35 P. M., on 1st May, arriving at Vienna early next morning.\"\n",
        "x_test = t.texts_to_sequences([test_example])\n",
        "x_test = pad_sequences(x_test, maxlen=max_len, padding='post')\n",
        "print(x_test)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[42 43  5 44 45 46 47  8 48 49 50  5 51 52 53 54  0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y9dsZSQnrqoU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0ed8b9be-3744-41f4-ad43-f3f4c0b41789"
      },
      "cell_type": "code",
      "source": [
        "preds = model.predict(x_test)\n",
        "print(preds)\n",
        "import numpy as np\n",
        "print(np.argmax(preds))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.3116142  0.38663843 0.3017474 ]]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G-Kuwvqcfptq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Convert the model"
      ]
    },
    {
      "metadata": {
        "id": "nyo2Q_ehe2RT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5a04734c-8b47-4a4d-a04f-aa488565e6cf"
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import tensorflowjs as tfjs\n",
        "\n",
        "metadata_json_path = os.path.join(MODEL_DIR, 'metadata.json')\n",
        "json.dump(metadata, open(metadata_json_path, 'wt'))\n",
        "tfjs.converters.save_keras_model(model, MODEL_DIR)\n",
        "print('\\nSaved model artifcats in directory: %s' % MODEL_DIR)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Saved model artifcats in directory: /content/DeepLearning/hw4/DeepLearning/hw4/model_js\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z609mw1aj-RJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Write an index.html and an index.js file configured to load our model."
      ]
    },
    {
      "metadata": {
        "id": "IoFAxt8nj9fp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index_html = \"\"\"\n",
        "<!doctype html>\n",
        "\n",
        "<body>\n",
        "  <style>\n",
        "    #textfield {\n",
        "      font-size: 120%;\n",
        "      width: 60%;\n",
        "      height: 200px;\n",
        "    }\n",
        "  </style>\n",
        "  <h1>\n",
        "    Title\n",
        "  </h1>\n",
        "  <hr>\n",
        "  <div class=\"create-model\">\n",
        "    <button id=\"load-model\" style=\"display:none\">Load model</button>\n",
        "  </div>\n",
        "  <div>\n",
        "    <div>\n",
        "      <span>Vocabulary size: </span>\n",
        "      <span id=\"vocabularySize\"></span>\n",
        "    </div>\n",
        "    <div>\n",
        "      <span>Max length: </span>\n",
        "      <span id=\"maxLen\"></span>\n",
        "    </div>\n",
        "  </div>\n",
        "  <hr>\n",
        "  <div>\n",
        "    <select id=\"example-select\" class=\"form-control\">\n",
        "      <option value=\"example1\">Alice's Adventures in Wonderland</option>\n",
        "      <option value=\"example2\">Dracula</option>\n",
        "      <option value=\"example3\">The Iliad</option>\n",
        "    </select>\n",
        "  </div>\n",
        "  <div>\n",
        "    <textarea id=\"text-entry\"></textarea>\n",
        "  </div>\n",
        "  <hr>\n",
        "  <div>\n",
        "    <span id=\"status\">Standing by.</span>\n",
        "  </div>\n",
        "\n",
        "  <script src='https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js'></script>\n",
        "  <script src='index.js'></script>\n",
        "</body>\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-JsQLbLnkhhk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "index_js = \"\"\"\n",
        "const HOSTED_URLS = {\n",
        "  model:\n",
        "      'model_js/model.json',\n",
        "  metadata:\n",
        "      'model_js/metadata.json'\n",
        "};\n",
        "\n",
        "const examples = {\n",
        "  'example1':\n",
        "      'Alice was beginning to get very tired of sitting by her sister on the bank.',\n",
        "  'example2':\n",
        "      'Buda-Pesth seems a wonderful place.',\n",
        "  'example3':\n",
        "      'Scepticism was as much the result of knowledge, as knowledge is of scepticism.'      \n",
        "};\n",
        "\n",
        "function status(statusText) {\n",
        "  console.log(statusText);\n",
        "  document.getElementById('status').textContent = statusText;\n",
        "}\n",
        "\n",
        "function showMetadata(metadataJSON) {\n",
        "  document.getElementById('vocabularySize').textContent =\n",
        "      metadataJSON['vocabulary_size'];\n",
        "  document.getElementById('maxLen').textContent =\n",
        "      metadataJSON['max_len'];\n",
        "}\n",
        "\n",
        "function settextField(text, predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  textField.value = text;\n",
        "  doPredict(predict);\n",
        "}\n",
        "\n",
        "function setPredictFunction(predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  textField.addEventListener('input', () => doPredict(predict));\n",
        "}\n",
        "\n",
        "function disableLoadModelButtons() {\n",
        "  document.getElementById('load-model').style.display = 'none';\n",
        "}\n",
        "\n",
        "function doPredict(predict) {\n",
        "  const textField = document.getElementById('text-entry');\n",
        "  const result = predict(textField.value);\n",
        "  score_string = \"Class scores: \";\n",
        "  for (var x in result.score) {\n",
        "    score_string += x + \" ->  \" + result.score[x].toFixed(3) + \", \"\n",
        "  }\n",
        "  //console.log(score_string);\n",
        "  status(\n",
        "      score_string + ' elapsed: ' + result.elapsed.toFixed(3) + ' ms)');\n",
        "}\n",
        "\n",
        "function prepUI(predict) {\n",
        "  setPredictFunction(predict);\n",
        "  const testExampleSelect = document.getElementById('example-select');\n",
        "  testExampleSelect.addEventListener('change', () => {\n",
        "    settextField(examples[testExampleSelect.value], predict);\n",
        "  });\n",
        "  settextField(examples['example1'], predict);\n",
        "}\n",
        "\n",
        "async function urlExists(url) {\n",
        "  status('Testing url ' + url);\n",
        "  try {\n",
        "    const response = await fetch(url, {method: 'HEAD'});\n",
        "    return response.ok;\n",
        "  } catch (err) {\n",
        "    return false;\n",
        "  }\n",
        "}\n",
        "\n",
        "async function loadHostedPretrainedModel(url) {\n",
        "  status('Loading pretrained model from ' + url);\n",
        "  try {\n",
        "    const model = await tf.loadModel(url);\n",
        "    status('Done loading pretrained model.');\n",
        "    disableLoadModelButtons();\n",
        "    return model;\n",
        "  } catch (err) {\n",
        "    console.error(err);\n",
        "    status('Loading pretrained model failed.');\n",
        "  }\n",
        "}\n",
        "\n",
        "async function loadHostedMetadata(url) {\n",
        "  status('Loading metadata from ' + url);\n",
        "  try {\n",
        "    const metadataJson = await fetch(url);\n",
        "    const metadata = await metadataJson.json();\n",
        "    status('Done loading metadata.');\n",
        "    return metadata;\n",
        "  } catch (err) {\n",
        "    console.error(err);\n",
        "    status('Loading metadata failed.');\n",
        "  }\n",
        "}\n",
        "\n",
        "class Classifier {\n",
        "\n",
        "  async init(urls) {\n",
        "    this.urls = urls;\n",
        "    this.model = await loadHostedPretrainedModel(urls.model);\n",
        "    await this.loadMetadata();\n",
        "    return this;\n",
        "  }\n",
        "\n",
        "  async loadMetadata() {\n",
        "    const metadata =\n",
        "        await loadHostedMetadata(this.urls.metadata);\n",
        "    showMetadata(metadata);\n",
        "    this.maxLen = metadata['max_len'];\n",
        "    console.log('maxLen = ' + this.maxLen);\n",
        "    this.wordIndex = metadata['word_index']\n",
        "  }\n",
        "\n",
        "  predict(text) {\n",
        "    // Convert to lower case and remove all punctuations.\n",
        "    const inputText =\n",
        "        text.trim().toLowerCase().replace(/(\\.|\\,|\\!)/g, '').split(' ');\n",
        "    // Look up word indices.\n",
        "    const inputBuffer = tf.buffer([1, this.maxLen], 'float32');\n",
        "    for (let i = 0; i < inputText.length; ++i) {\n",
        "      const word = inputText[i];\n",
        "      inputBuffer.set(this.wordIndex[word], 0, i);\n",
        "      //console.log(word, this.wordIndex[word], inputBuffer);\n",
        "    }\n",
        "    const input = inputBuffer.toTensor();\n",
        "    //console.log(input);\n",
        "\n",
        "    status('Running inference');\n",
        "    const beginMs = performance.now();\n",
        "    const predictOut = this.model.predict(input);\n",
        "    //console.log(predictOut.dataSync());\n",
        "    const score = predictOut.dataSync();//[0];\n",
        "    predictOut.dispose();\n",
        "    const endMs = performance.now();\n",
        "\n",
        "    return {score: score, elapsed: (endMs - beginMs)};\n",
        "  }\n",
        "};\n",
        "\n",
        "async function setup() {\n",
        "  if (await urlExists(HOSTED_URLS.model)) {\n",
        "    status('Model available: ' + HOSTED_URLS.model);\n",
        "    const button = document.getElementById('load-model');\n",
        "    button.addEventListener('click', async () => {\n",
        "      const predictor = await new Classifier().init(HOSTED_URLS);\n",
        "      prepUI(x => predictor.predict(x));\n",
        "    });\n",
        "    button.style.display = 'inline-block';\n",
        "  }\n",
        "\n",
        "  status('Standing by.');\n",
        "}\n",
        "\n",
        "setup();\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KbvVVh1rkmga",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('index.html','w') as f:\n",
        "  f.write(index_html)\n",
        "  \n",
        "with open('index.js','w') as f:\n",
        "  f.write(index_js)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0YtvaoazkuRT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51d7458d-aebb-4137-84ba-e287d5f2e43b"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "index.html  index.js  model_js\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z3NX9FVLiBO7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Commit and push everything. Note: we're storing large binary files in GitHub, this isn't ideal (if you want to deploy a model down the road, better to host it in a cloud storage bucket)."
      ]
    },
    {
      "metadata": {
        "id": "RoL5aoRUh5DB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "52812474-f27f-442f-e7cc-0dfca908e6ba"
      },
      "cell_type": "code",
      "source": [
        "!git add . \n",
        "!git commit -m \"colab -> github\"\n",
        "!git push https://{USER_NAME}:{TOKEN}@github.com/{USER_NAME}/{repo_path}/ master"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[master 7ae24cd] colab -> github\n",
            " 2 files changed, 1 insertion(+), 1 deletion(-)\n",
            " rewrite hw4/model_js/group1-shard1of1 (99%)\n",
            "Counting objects: 6, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (5/5), done.\n",
            "Writing objects: 100% (6/6), 31.02 KiB | 15.51 MiB/s, done.\n",
            "Total 6 (delta 2), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/yyao-lulu/DeepLearning/\n",
            "   46f07a0..7ae24cd  master -> master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WDoo_fDVic2E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "All done! Hopefully everything worked. You may need to wait a few moments for the changes to appear in your site. If not working, check the JavaScript console for errors (in Chrome: View -> Developer -> JavaScript Console)."
      ]
    },
    {
      "metadata": {
        "id": "1V1QLCxlikOI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a1cc305-a94e-4138-d016-8e5f2756011c"
      },
      "cell_type": "code",
      "source": [
        "print(\"Now, visit https://%s.github.io/%s/%s/\" % (USER_NAME, repo_path, SITE_NAME))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now, visit https://yyao-lulu.github.io/DeepLearning/hw4/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mnN6zAHWqPnR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If you are debugging and Chrome is failing to pick up your changes, though you've verified they're present in your GitHub repo, see the second answer to: https://superuser.com/questions/89809/how-to-force-refresh-without-cache-in-google-chrome"
      ]
    }
  ]
}